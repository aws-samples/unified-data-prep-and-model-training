{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import AutoML\n",
    "\n",
    "# This script expects an input of a CSV file with a header.\n",
    "# It that input file, saves the header as a var, strips it out,\n",
    "# and then uploads the header-less CSV back to S3 for the AutoPilot\n",
    "# system to process as an input\n",
    "\n",
    "# You only need to modify these three lines to customize to your env\n",
    "\n",
    "autopilot_experiment_name = \"<YOUR_EXPERIMENT_NAME>\"\n",
    "holdout_sample_bucket = '<YOUR_HOLDOUT_SAMPLE_BUCKET_NAME>'\n",
    "holdout_sample_key = '<YOUR_HOLDOUT_SAMPLE_KEY_NAME>'\n",
    "\n",
    "\n",
    "holdout_sample_path=f's3://{holdout_sample_bucket}/{holdout_sample_key}'\n",
    "holdout_sample_no_header_key = f'{holdout_sample_key}.no_header'\n",
    "holdout_sample_no_header_full_path=f's3://{holdout_sample_bucket}/{holdout_sample_no_header_key}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_file(holdout_sample_bucket, holdout_sample_key, holdout_sample_no_header_key):\n",
    "    \n",
    "    import boto3\n",
    "    \n",
    "    # copy the file locally\n",
    "    \n",
    "    print(\"Copying file locally...\", end='')\n",
    "    obj = boto3.resource('s3').Object(holdout_sample_bucket, holdout_sample_key)\n",
    "    temp_file = obj.get()['Body'].read().decode()\n",
    "    print(\"done.\")\n",
    "\n",
    "    # grab and save the header\n",
    "\n",
    "    csv_header = temp_file.partition('\\n')[0].split(',')\n",
    "    print(f'Retrieved header: {csv_header}')\n",
    "\n",
    "    # we'll append these additional columns to the header for later \n",
    "    csv_header +=  ['Prediction','PredictionProb']\n",
    "\n",
    "    # remove the header from temp file\n",
    "\n",
    "    headerless_csv_body = temp_file.split(\"\\n\",1)[1]\n",
    "\n",
    "    # upload back to S3 headerless\n",
    "\n",
    "    print(f'Writing headerless output CSV...', end='')\n",
    "    headerless_csv_object = boto3.resource('s3').Object(holdout_sample_bucket, holdout_sample_no_header_key)\n",
    "    headerless_csv_object.put(Body=headerless_csv_body)\n",
    "    print(\"done.\")\n",
    "\n",
    "    return csv_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_header = process_csv_file(holdout_sample_bucket, holdout_sample_key, holdout_sample_no_header_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML.attach(auto_ml_job_name=autopilot_experiment_name)\n",
    "candidate_name=None\n",
    "#candidate_name=\"<YOUR_CANDIDATE_NAME>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_experiment=automl.describe_auto_ml_job()\n",
    "all_candidates = automl.list_candidates(sort_by='FinalObjectiveMetricValue',\n",
    "                                        sort_order='Descending',\n",
    "                                        max_results=100)\n",
    "best_candidate = automl_experiment['BestCandidate']\n",
    "best_candidate_name = best_candidate['CandidateName']\n",
    "inference_response_keys = [\"predicted_label\", \"probability\"]\n",
    "\n",
    "model = automl.create_model(name=best_candidate_name, \n",
    "                  candidate=best_candidate, \n",
    "                  inference_response_keys=inference_response_keys)\n",
    "\n",
    "if candidate_name is not None:\n",
    "    \n",
    "    for candidate in all_candidates:\n",
    "        if candidate['CandidateName'] == \"\":\n",
    "            candidate_name = candidate['CandidateName']\n",
    "            model = automl.create_model(name=candidate_name, \n",
    "                                        candidate=candidate, \n",
    "                                        inference_response_keys=inference_response_keys)\n",
    "            break \n",
    "            model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import HTML\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "best_candidate_name=best_candidate['CandidateName']\n",
    "model_artifact_loc=best_candidate['CandidateProperties']['CandidateArtifactLocations']['ModelInsights']\n",
    "best_model_artifact_loc=model_artifact_loc+'/'+best_candidate_name\n",
    "model_insights_pdf_report=best_model_artifact_loc+\"/report.pdf\"\n",
    "model_insights_pdf_report_uri=urlparse(model_insights_pdf_report)\n",
    "\n",
    "content_object = s3.Object(model_insights_pdf_report_uri.netloc, model_insights_pdf_report_uri.path[1:])\n",
    "file_content = content_object.get()['Body'].read()\n",
    "\n",
    "print(model_insights_pdf_report_uri.netloc)\n",
    "IPython.display.display_pdf(file_content,raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = model.transformer(instance_count=1, \n",
    "                                instance_type='ml.m5.xlarge',\n",
    "                                assemble_with='Line',\n",
    "                                output_path=holdout_sample_path, accept=\"text/csv\")\n",
    "\n",
    "transformer.transform(data=holdout_sample_no_header_full_path,\n",
    "                      split_type='Line',\n",
    "                      content_type='text/csv',\n",
    "                      input_filter='$[0:7]',\n",
    "                      join_source=\"Input\",\n",
    "                      wait=False)\n",
    "\n",
    "print(\"Starting transform job {}\".format(transformer._current_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name='us-east-2')\n",
    "desc = sm.describe_transform_job(TransformJobName=transformer._current_job_name)\n",
    "\n",
    "while desc['TransformJobStatus']=='InProgress':\n",
    "    desc = sm.describe_transform_job(TransformJobName=transformer._current_job_name)\n",
    "    print(desc['TransformJobName']+' is in progress')\n",
    "    sleep(5)\n",
    "\n",
    "if desc['TransformJobStatus']=='Completed':\n",
    "    path=desc['TransformOutput']['S3OutputPath']\n",
    "    s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "    # get data file names\n",
    "    filenames = s3.glob(path + \"/*.out\")\n",
    "    dfs = []\n",
    "    for filename in filenames:\n",
    "        dfs.append(pd.read_csv('s3://'+filename, header=None))\n",
    "\n",
    "    output_df = pd.concat(dfs, ignore_index=True)\n",
    "else:\n",
    "    print(desc['TransformJobName']+' Failed!') \n",
    "    \n",
    "\n",
    "print(f\"{desc['TransformJobStatus']}\")\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.columns = csv_header\n",
    "output_df=output_df.iloc[1:,:]\n",
    "output_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=output_df.convert_dtypes()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(output_df['Outcome'].astype(str).astype(int), output_df['Prediction'])\n",
    "f = sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(output_df['Outcome'].astype(str).astype(int), output_df['PredictionProb'])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,estimator_name='Holdout/Test Data - ROC curve')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "prec, recall, _ = precision_recall_curve(output_df['Outcome'].astype(str).astype(int), output_df['PredictionProb'])\n",
    "average_precision= metrics.average_precision_score(output_df['Outcome'].astype(str).astype(int), output_df['PredictionProb'] )\n",
    "pr_display = PrecisionRecallDisplay(precision=prec, recall=recall, average_precision=average_precision, estimator_name='Holdout/Test Data - AUPRC curve')\n",
    "pr_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
